title: 2015年3月4日阿里数据挖掘工程师电话面试总结
date: 2015-03-09 22:38:20
categories: 总结
tags: [我自己,面试]
---
下面对面试官所问的一些问题做汇总：
### 1.Feature，即特征是什么？
他原本问我的是我做的数字识别里面的特征是什么，以我之前对特征的理解，比如神经网络，我认为是参数层所表达的便是特征。因此，我才不能明白他所说的特征到底是什么含义。
现在我知道了，特征便是输入数据。描述一个苹果的特征包括苹果的大小、味道、颜色等，这些叫做特征。对于神经网络，每一层的输入都可以称为特征，只不过有些特征不能很明白地讲明白而已。

### 2.Logistic Regression, 为什么是这样的回归？
Logistic Regression表面上是回归，实际上却是做的分类相关的东西。Logistic Regression的输出是有统计含义的，可以表述为y=+1的概率。在我们对数据特征进行加权求和后，为了将其变换为y=+1的概率，需要一种能从$[-\infty,+\infty]$转换到$[0,1]$上的函数，比如sigmoid函数。
那为什么使用sigmoid函数呢，那就是Generalized Linear Model所解决的问题了。
能否使用最小方均误差进行最小化呢？最好不，因为最小方均误差的$function$是非凸函数。
一般我们使用Cross-Entropy Error，交叉熵误差进行最小化。

### 3.有哪些距离公式？他们的优点和缺点是什么?
1.欧几里得距离
需要将数据标准化，以避免量纲不同导致的错误。
优点：简单
缺点：没有考虑分量之间的相关性
2.马氏距离
如果分量之间有相关性，那么就需要使用协方差矩阵来消除相关性。
3.闽科夫斯基距离——欧式距离的推广
4.曼哈顿距离，$p=1$
5.切比雪夫距离，$p=\infty$
6.汉明距离
7.Jaccard系数
一般使用集合表示。
8.Tanimoto系数(广义Jaccard系数)
9.皮尔逊相关系数
特征减去均值后的余弦相似度。
10.余弦相似度
11.调整余弦相似度
12.基于权重的距离
13.KL散度
用于计算两个概率之间的距离。

### 4.除了K-means，你还知道哪些聚类算法？
1 Partitioning approach
包括 K-means, K-medoids
2 Model-based
有GMM(混合高斯模型)
3 Dimensionality Reduction Approach
先降维，后聚类
包括 Spectral Clustering(谱聚类), Ncut
4 一些层次聚类算法(不需要熟悉)

K-means和GMM比较
1 K-means的目标函数是最小化Total Squared Distance，而GMM是最大化似然函数
2 两者都可以使用EM算法来解决问题
3 K-means要求类与类分布函数是相同的，而GMM不要求

### 5.K-means中的类别数N如何确定
1 经验
2 在某个空间内对K逐一鉴别，找出最好的k
3 使用一些能自动判定K的聚类方法，比如G-means